{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5e61d4-9181-4950-ba4e-0293caabed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "from io import StringIO\n",
    "from functools import wraps\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pstats\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from pympler import asizeof\n",
    "\n",
    "from time_res_util import get_compiled_NF_model\n",
    "from momentum_prediction_util import load_defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453c96b8-3afc-48b2-9da5-bdd69f5c151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_function(func):\n",
    "    \"\"\"\n",
    "    Decorator to profile a specific function using cProfile\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        profiler = cProfile.Profile()\n",
    "        try:\n",
    "            return profiler.runcall(func, *args, **kwargs)\n",
    "        finally:\n",
    "            s = StringIO()\n",
    "            stats = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "            stats.print_stats(20)  # Print top 20 time-consuming operations\n",
    "            print(s.getvalue())\n",
    "    return wrapper\n",
    "\n",
    "'''MEMORY PROFILING'''\n",
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=3):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4671432-d096-45c6-b89a-1091cc3f240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/core.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "inputProcessedData = \"./data/processed_data/no_inner_old_SIDIS_run_2_1000events.json\"\n",
    "model_compile = get_compiled_NF_model()\n",
    "processed_data = load_defaultdict(inputProcessedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98fa472-3598-4944-9130-6e7df78e0ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data in new_prepare_nn_input...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:20<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling took 20.35903811454773 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50000\n",
    "device = 'cuda'\n",
    "normalizing_flow = model_compile\n",
    "\n",
    "nn_input = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list)))))\n",
    "nn_output = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list)))))\n",
    "\n",
    "all_context = []\n",
    "all_time_pixels = []\n",
    "all_metadata = []\n",
    "num_pixel_list = [\"num_pixels_high_z\",\"num_pixels_low_z\"]\n",
    "print(\"Processing data in new_prepare_nn_input...\")\n",
    "for event_idx, event_data in tqdm(processed_data.items()):\n",
    "    for stave_idx, stave_data in event_data.items():\n",
    "        for layer_idx, layer_data in stave_data.items():\n",
    "            for segment_idx, segment_data in layer_data.items():\n",
    "                trueID_list = []\n",
    "                for particle_id, particle_data in segment_data.items():\n",
    "#                         print(f\"keys of particle data: {particle_data.keys()}\")\n",
    "#                         print(f\"types: {type(particle_data['z_pos'])},{type(particle_data['hittheta'])},{type(particle_data['hitmomentum'])}\")\n",
    "                    base_context = torch.tensor([particle_data['z_pos'], particle_data['hittheta'], particle_data['hitmomentum']], \n",
    "                                                dtype=torch.float32)\n",
    "                    base_time_pixels_low = torch.tensor([particle_data['time'], particle_data['num_pixels_low_z']], \n",
    "                                                    dtype=torch.float32)\n",
    "                    base_time_pixels_high = torch.tensor([particle_data['time'], particle_data['num_pixels_high_z']], \n",
    "                                                    dtype=torch.float32)\n",
    "                    if particle_data['trueID'] not in  trueID_list:\n",
    "                        trueID_list.append(particle_data['trueID'])\n",
    "                    for SiPM_idx in range(2):\n",
    "                        z_pos = particle_data['z_pos']\n",
    "                        context = base_context.clone()\n",
    "                        context[0] = z_pos\n",
    "                        num_pixel_tag = num_pixel_list[SiPM_idx]\n",
    "                        all_context.append(context.repeat(particle_data[num_pixel_tag], 1))\n",
    "                        if(SiPM_idx == 0):\n",
    "                            all_time_pixels.append(base_time_pixels_high.repeat(particle_data[num_pixel_tag], 1))\n",
    "                        else:\n",
    "                            all_time_pixels.append(base_time_pixels_low.repeat(particle_data[num_pixel_tag], 1))\n",
    "                        # Assuming particle_data is a dictionary-like object and trueID_list is defined\n",
    "                        fields = [\n",
    "                            'truemomentum', 'trueID', 'truePID', 'hitID', 'hitPID', \n",
    "                            'truetheta', 'truephi', 'strip_x', 'strip_y', 'strip_z', \n",
    "                            'hit_x', 'hit_y', 'hit_z', 'KMU_trueID', 'KMU_truePID', \n",
    "                            'KMU_true_phi', 'KMU_true_momentum_mag', 'KMU_endpoint_x', \n",
    "                            'KMU_endpoint_y', 'KMU_endpoint_z'\n",
    "                        ]\n",
    "\n",
    "                        # Print types of each particle_data field\n",
    "#                             for field in fields:\n",
    "#                                 value = particle_data.get(field, None)\n",
    "#                                 print(f\"{field}: {type(value)}\")\n",
    "\n",
    "#                             # Print the type of len(trueID_list)\n",
    "#                             print(f\"len(trueID_list): {type(len(trueID_list))}\")\n",
    "\n",
    "                        all_metadata.extend([(event_idx,stave_idx, layer_idx,segment_idx, SiPM_idx, particle_data['truemomentum'],particle_data['trueID'],particle_data['truePID'],particle_data['hitID'],particle_data['hitPID'],particle_data['truetheta'],particle_data['truephi'],particle_data['strip_x'],particle_data['strip_y'],particle_data['strip_z'],len(trueID_list),particle_data['hit_x'],particle_data['hit_y'],particle_data['hit_z'],particle_data['KMU_trueID'],particle_data['KMU_truePID'],particle_data['KMU_true_phi'],particle_data['KMU_true_momentum_mag'],particle_data['KMU_endpoint_x'],particle_data['KMU_endpoint_y'],particle_data['KMU_endpoint_z'])] * particle_data[num_pixel_tag])\n",
    "\n",
    "all_context = torch.cat(all_context)\n",
    "all_time_pixels = torch.cat(all_time_pixels)\n",
    "\n",
    "print(\"Sampling data...\")\n",
    "sampled_data = []\n",
    "begin = time.time()\n",
    "for i in tqdm(range(0, len(all_context), batch_size)):\n",
    "    batch_end = min(i + batch_size, len(all_context))\n",
    "    batch_context = all_context[i:batch_end].to(device)\n",
    "    batch_time_pixels = all_time_pixels[i:batch_end]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = abs(normalizing_flow.sample(num_samples=len(batch_context), context=batch_context)[0]).squeeze(1)\n",
    "\n",
    "    sampled_data.extend(samples.cpu() + batch_time_pixels[:, 0])\n",
    "end = time.time()\n",
    "print(f\"sampling took {end - begin} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181f899-6b12-451e-83b5-e4531ef85438",
   "metadata": {},
   "source": [
    "### ORIGINAL W/nested dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d8fbdd-3042-4a3a-8d64-c03b3a58c998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reorganizing data...\n",
      "reorganizing took 9.405727624893188 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Reorganizing data...\")\n",
    "begin = time.time()\n",
    "for (event,stave, layer,segment, SiPM, momentum,trueID,truePID,hitID,hitPID,theta,phi,strip_x,strip_y,strip_z,trueID_list_len,hit_x,hit_y,hit_z,KMU_trueID,KMU_truePID,KMU_true_phi,KMU_true_momentum_mag,KMU_endpoint_x,KMU_endpoint_y,KMU_endpoint_z), sample in zip(all_metadata, sampled_data):\n",
    "    nn_input[event][stave][layer][segment][SiPM].append(sample)\n",
    "\n",
    "    nn_output[event][stave][layer][segment][SiPM].append(torch.tensor([momentum,trueID,truePID,hitID,hitPID,theta,phi,strip_x,strip_y,strip_z,trueID_list_len,hit_x,hit_y,hit_z,KMU_trueID,KMU_truePID,KMU_true_phi,KMU_true_momentum_mag,KMU_endpoint_x,KMU_endpoint_y,KMU_endpoint_z]))\n",
    "end = time.time()\n",
    "print(f\"reorganizing took {end - begin} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c691a4-dd4a-4aac-a061-0e04aaafded3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.01953887939453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asizeof.asizeof(nn_output) / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3212d7b-3b85-4fd8-812b-c0d397296da4",
   "metadata": {},
   "source": [
    "### NEW WITH ONE DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f67caad-8d3c-498d-b9e7-d699b4a6ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn_input = defaultdict(list)\n",
    "new_nn_output = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6466ce49-a74e-4c59-be6d-52e4bd89a33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reorganizing data...\n",
      "reorganizing took 11.132388830184937 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Reorganizing data...\")\n",
    "begin = time.time()\n",
    "for (event,stave, layer,segment, SiPM, momentum,trueID,truePID,hitID,hitPID,theta,phi,strip_x,strip_y,strip_z,trueID_list_len,hit_x,hit_y,hit_z,KMU_trueID,KMU_truePID,KMU_true_phi,KMU_true_momentum_mag,KMU_endpoint_x,KMU_endpoint_y,KMU_endpoint_z), sample in zip(all_metadata, sampled_data):\n",
    "    new_nn_input[f\"{event}_{stave}_{layer}_{segment}_{SiPM}\"].append(sample)\n",
    "\n",
    "    new_nn_output[f\"{event}_{stave}_{layer}_{segment}_{SiPM}\"].append(torch.tensor([momentum,trueID,truePID,hitID,hitPID,theta,phi,strip_x,strip_y,strip_z,trueID_list_len,hit_x,hit_y,hit_z,KMU_trueID,KMU_truePID,KMU_true_phi,KMU_true_momentum_mag,KMU_endpoint_x,KMU_endpoint_y,KMU_endpoint_z]))\n",
    "end = time.time()\n",
    "print(f\"reorganizing took {end - begin} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a31f33-6995-45bd-93ff-451301186e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.6405258178711"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asizeof.asizeof(new_nn_output) / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f44042-f276-424b-ab1f-10719fd2c212",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data in new_prepare_nn_input...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:16<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling took 16.07623791694641 seconds\n",
      "Reorganizing data...\n",
      "reorganizing took 15.902801513671875 seconds\n",
      "         2490697 function calls (2433322 primitive calls) in 32.656 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 245 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    4.117    4.117   32.658   32.658 /tmp/ipykernel_376719/3175385229.py:1(new_prepare_nn_input)\n",
      "       15    0.009    0.001   12.776    0.852 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/core.py:286(sample)\n",
      "22695/255    0.090    0.000   12.766    0.050 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1549(_wrapped_call_impl)\n",
      "22695/255    0.107    0.000   12.764    0.050 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1555(_call_impl)\n",
      "      120    0.002    0.000   12.568    0.105 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/flows/neural_spline/wrapper.py:230(forward)\n",
      "      120    0.005    0.000   12.564    0.105 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/flows/affine/autoregressive.py:29(inverse)\n",
      "   711441   11.960    0.000   11.960    0.000 {built-in method torch.tensor}\n",
      "      120    0.001    0.000   10.696    0.089 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/flows/neural_spline/autoregressive.py:133(_elementwise_inverse)\n",
      "      120    0.009    0.000   10.695    0.089 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/flows/neural_spline/autoregressive.py:94(_elementwise)\n",
      "      120   10.218    0.085   10.677    0.089 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/utils/splines.py:16(unconstrained_rational_quadratic_spline)\n",
      "     7403    0.034    0.000    3.253    0.000 {method 'extend' of 'list' objects}\n",
      "       15    0.000    0.000    3.219    0.215 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/torch/_tensor.py:1033(__iter__)\n",
      "       15    3.166    0.211    3.218    0.215 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "      120    0.025    0.000    1.848    0.015 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/nets/made.py:296(forward)\n",
      "     3120    0.272    0.000    1.740    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/nets/made.py:201(forward)\n",
      "     6480    0.270    0.000    0.584    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/nets/made.py:80(forward)\n",
      "      120    0.357    0.003    0.445    0.004 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/utils/splines.py:100(rational_quadratic_spline)\n",
      "     9720    0.431    0.000    0.431    0.000 {built-in method torch._C._nn.linear}\n",
      "  1415810    0.187    0.000    0.187    0.000 {method 'append' of 'list' objects}\n",
      "     6240    0.011    0.000    0.175    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/torch/nn/modules/activation.py:103(forward)\n",
      "\n",
      "\n",
      "\n",
      "new_prepare_nn_input took 33.543376207351685 seconds\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "nn_input,nn_output = new_prepare_nn_input(processed_data, model_compile,batch_size = 50000)\n",
    "end = time.time()\n",
    "print(f\"new_prepare_nn_input took {(end - begin)} seconds\")\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "\n",
    "display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a37fb20d-26ba-4212-ba46-0cb1e234463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 lines\n",
      "#1: ipykernel_376719/3175385229.py:78: 60573.6 KiB\n",
      "    nn_output[event][stave][layer][segment][SiPM].append(torch.tensor([momentum,trueID,truePID,hitID,hitPID,theta,phi,strip_x,strip_y,strip_z,trueID_list_len,hit_x,hit_y,hit_z,KMU_trueID,KMU_truePID,KMU_true_phi,KMU_true_momentum_mag,KMU_endpoint_x,KMU_endpoint_y,KMU_endpoint_z]))\n",
      "#2: torch/_tensor.py:1053: 54715.7 KiB\n",
      "    return iter(self.unbind(0))\n",
      "#3: ipykernel_376719/3175385229.py:76: 5843.8 KiB\n",
      "    nn_input[event][stave][layer][segment][SiPM].append(sample)\n",
      "209 other: 349.9 KiB\n",
      "Total allocated size: 121483.0 KiB\n"
     ]
    }
   ],
   "source": [
    "display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303ecdf-6e27-4a3a-9458-151e6581ca00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
