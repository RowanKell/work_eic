{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd528141-5e03-4724-a3ac-1a3749c7ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from util import get_layer, theta_func,create_layer_map\n",
    "from reco import calculate_num_pixels_z_dependence\n",
    "import matplotlib.pyplot as plot\n",
    "import time\n",
    "from collections import defaultdict\n",
    "# Get device to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import os\n",
    "def checkdir(path):\n",
    "    if not os.path.exists(path): \n",
    "        os.makedirs(path)\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52353658-e1ee-4fa5-8f48-a44a5267203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_map, super_layer_map = create_layer_map()\n",
    "x_hit_pos = []\n",
    "z_pos_list = []\n",
    "layer_list = []\n",
    "\n",
    "def process_root_file(file_path):\n",
    "    print(\"began processing\")\n",
    "    with uproot.open(file_path) as file:\n",
    "        tree = file[\"events/HcalBarrelHits\"]\n",
    "        \n",
    "        \n",
    "        z_pos = tree[\"HcalBarrelHits.position.z\"].array(library=\"np\")\n",
    "        x_pos = tree[\"HcalBarrelHits.position.x\"].array(library=\"np\")\n",
    "        energy = tree[\"HcalBarrelHits.EDep\"].array(library=\"np\")\n",
    "        momentum_x = tree[\"HcalBarrelHits.momentum.x\"].array(library=\"np\")\n",
    "        momentum_y = tree[\"HcalBarrelHits.momentum.y\"].array(library=\"np\")\n",
    "        momentum_z = tree[\"HcalBarrelHits.momentum.z\"].array(library=\"np\")\n",
    "        hit_time = tree[\"HcalBarrelHits.time\"].array(library=\"np\")\n",
    "        mc_hit_idx = file[\"events/_HcalBarrelHits_MCParticle/_HcalBarrelHits_MCParticle.index\"].array(library=\"np\")  # Add PDG code for particle identification\n",
    "        print(\"finished loading branches\")\n",
    "        \n",
    "        processed_data = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "        \n",
    "        for event_idx in range(len(z_pos)):\n",
    "            energy_per_layer_particle = defaultdict(lambda: defaultdict(float))\n",
    "            first_hit_per_layer_particle = defaultdict(dict)\n",
    "            \n",
    "            # First pass: collect first hit data and calculate energy per layer per particle\n",
    "            for hit_idx in range(len(z_pos[event_idx])):\n",
    "                z = z_pos[event_idx][hit_idx]\n",
    "                x = x_pos[event_idx][hit_idx]\n",
    "                e = energy[event_idx][hit_idx]\n",
    "                momentum = (momentum_x[event_idx][hit_idx],\n",
    "                            momentum_y[event_idx][hit_idx],\n",
    "                            momentum_z[event_idx][hit_idx])\n",
    "                momentum_mag = np.linalg.norm(momentum)\n",
    "                theta = theta_func(momentum_x[event_idx][hit_idx], momentum_y[event_idx][hit_idx], momentum_z[event_idx][hit_idx])\n",
    "                layer = get_layer(x)\n",
    "                particle_id = mc_hit_idx[event_idx][hit_idx]\n",
    "                \n",
    "                energy_per_layer_particle[layer][particle_id] += e\n",
    "                \n",
    "                if layer not in first_hit_per_layer_particle or particle_id not in first_hit_per_layer_particle[layer]:\n",
    "                    first_hit_per_layer_particle[layer][particle_id] = {\n",
    "                        \"z_pos\": z,\n",
    "                        \"x_pos\": x,\n",
    "                        \"momentum\": momentum_mag,\n",
    "                        \"theta\": theta,\n",
    "                        \"time\": hit_time[event_idx][hit_idx],\n",
    "                        \"mc_hit_idx\": particle_id\n",
    "                    }\n",
    "            \n",
    "            \n",
    "            # Second pass: process first hit with total layer energy per particle\n",
    "            for layer, particle_data in first_hit_per_layer_particle.items():\n",
    "                for particle_id, hit_data in particle_data.items():\n",
    "                    layer_particle_energy = energy_per_layer_particle[layer][particle_id]\n",
    "                    num_pixels = calculate_num_pixels_z_dependence(layer_particle_energy, hit_data[\"z_pos\"])\n",
    "#                     print(f\"layer:\\t\\t{layer}\\t|\\tparticle id:\\t{particle_id}\\t|\\tnum_pixels:\\t{num_pixels}\")\n",
    "                    hit_data[\"num_pixels\"] = int(np.floor(num_pixels))\n",
    "                    hit_data[\"layer_energy\"] = layer_particle_energy  # Store total layer energy for this particle\n",
    "                    processed_data[event_idx][layer][particle_id] = hit_data\n",
    "    \n",
    "    print(\"finished processing\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464fc9f8-bd77-438a-b4ab-df08d4458762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "began processing\n",
      "finished loading branches\n",
      "finished processing\n"
     ]
    }
   ],
   "source": [
    "pref = \"/hpc/group/vossenlab/rck32/\"\n",
    "# processed_data = process_root_file(pref + \"eic/work_eic/root_files/September_3/sector_scint/run_1_pip_0_8_10GeV_theta_90_500events.edm4hep.root\")\n",
    "processed_data = process_root_file(pref + \"eic/work_eic/root_files/September_3/sector_scint/run_1_mum_0_8_10GeV_theta_90_500events.edm4hep.root\")\n",
    "# processed_data = process_root_file(pref + \"eic/work_eic/root_files/September_3/sector_scint/run_1_n_0_8_10GeV_theta_90_5kevents.edm4hep.root\")\n",
    "# nn_input, nn_output = prepare_nn_input(processed_data, normalizing_flow_model)\n",
    "# prediction_input, prediction_output = prepare_prediction_input(nn_input, nn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7a9ff4-fb88-4272-b501-cb02f90f3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/core.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "import normflows as nf\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "today = x.strftime(\"%B_%d\")\n",
    "# particle = \"pi\"\n",
    "particle = \"mu\"\n",
    "\n",
    "# This data will be used for storing plots - today above works if you actually want today\n",
    "# today = \"July_26\"\n",
    "\n",
    "run_num = 7\n",
    "run_num_str = str(run_num)\n",
    "\n",
    "#NF Stuff\n",
    "\n",
    "K = 8 #num flows\n",
    "\n",
    "latent_size = 1 #dimension of PDF\n",
    "hidden_units = 256 #nodes in hidden layers\n",
    "hidden_layers = 26\n",
    "context_size = 3 #conditional variables for PDF\n",
    "num_context = 3\n",
    "\n",
    "K_str = str(K)\n",
    "batch_size= 2000\n",
    "hidden_units_str = str(hidden_units)\n",
    "hidden_layers_str = str(hidden_layers)\n",
    "batch_size_str = str(batch_size)\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units, \n",
    "                                                             num_context_channels=context_size)]\n",
    "    flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "\n",
    "# Set base distribution\n",
    "q0 = nf.distributions.DiagGaussian(1, trainable=False)\n",
    "    \n",
    "# Construct flow model\n",
    "model = nf.ConditionalNormalizingFlow(q0, flows)\n",
    "\n",
    "# Move model on GPU if available\n",
    "model = model.to(device)\n",
    "# model_date = \"August_03\"\n",
    "# today = \"August_03\"\n",
    "# model_path = \"models/\" + model_date + \"/\"\n",
    "# checkdir(model_path)\n",
    "\n",
    "model_path = \"/hpc/group/vossenlab/rck32/NF_time_res_models/\"\n",
    "\n",
    "samples_path = \"data/samples/\" + today + \"/\"\n",
    "checkdir(samples_path)\n",
    "\n",
    "test_data_path = \"data/test/\" + today + \"/\"\n",
    "checkdir(test_data_path)\n",
    "\n",
    "test_dist_path = \"plots/test_distributions/\" + today + \"/\"\n",
    "checkdir(test_dist_path)\n",
    "model.load(model_path + \"run_\" + run_num_str + \"_\" + str(num_context)+ \"context_\" +K_str +  \"flows_\" + hidden_layers_str+\"hl_\" + hidden_units_str+\"hu_\" + batch_size_str+\"bs.pth\")\n",
    "model = model.to(device)\n",
    "model_compile = torch.compile(model,mode = \"reduce-overhead\")\n",
    "model_compile = model_compile.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0a1f807-9070-4c1d-8236-0226bb1fee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_nn_input(processed_data, normalizing_flow, batch_size=1024):\n",
    "    flattened_data = []\n",
    "    event_indices = []\n",
    "    layer_indices = []\n",
    "    particle_indices = []\n",
    "\n",
    "    final_event_indices = []\n",
    "    final_layer_indices = []\n",
    "    final_particle_indices = []\n",
    "    \n",
    "    momentum_list = []\n",
    "    \n",
    "    context_list = []\n",
    "    running_pixel_idx = 0\n",
    "    for event_idx, event_data in processed_data.items():\n",
    "        primary_momentum = event_data[0][0][\"momentum\"]\n",
    "        for layer, particle_data in event_data.items():\n",
    "            for particle_id, hit_data in particle_data.items():\n",
    "                context = torch.tensor([hit_data['z_pos'], hit_data['theta'], hit_data['momentum']], dtype=torch.float32).repeat(hit_data['num_pixels'], 1)\n",
    "                flattened_data.append(torch.tensor([hit_data['time'], hit_data['num_pixels']]).repeat(hit_data['num_pixels'],1))\n",
    "                context_list.append(context)\n",
    "                for pixel_repeat_idx in range(hit_data['num_pixels']):\n",
    "                    final_event_indices.append(event_idx)\n",
    "                    final_layer_indices.append(layer)\n",
    "                    final_particle_indices.append(particle_id)\n",
    "                    momentum_list.append(primary_momentum.item())\n",
    "                \n",
    "#     final_event_indices = torch.cat(event_indices)\n",
    "#     final_layer_indices = torch.cat(layer_indices)\n",
    "#     final_particle_indices = torch.cat(particle_indices)\n",
    "    all_context = torch.cat(context_list).to(device)\n",
    "    all_time_pixels = torch.cat(flattened_data)\n",
    "    # Batch the flattened data\n",
    "    max_its = int(np.ceil(all_context.shape[0] / batch_size))\n",
    "    sampled_data = []\n",
    "    for batch_idx in tqdm(range(max_its)):\n",
    "        begin = batch_idx * batch_size\n",
    "        data_left = all_context.shape[0] - (batch_idx * batch_size)\n",
    "        end = min(begin + batch_size,begin + data_left)\n",
    "        add_times = all_time_pixels[begin:end]\n",
    "        context_batch = all_context[begin:end].to(device)\n",
    "        with torch.no_grad():\n",
    "            samples = abs(normalizing_flow.sample(num_samples=context_batch.shape[0], context=context_batch)[0]).squeeze(1)\n",
    "        adjusted_times = samples.detach().cpu() + add_times[:,0]\n",
    "        sampled_data.extend(adjusted_times)\n",
    "    # Reorganize sampled data\n",
    "    nn_input = defaultdict(lambda: defaultdict(list))\n",
    "    nn_output = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for i, (event, layer, particle) in enumerate(zip(final_event_indices, final_layer_indices, final_particle_indices)):\n",
    "        nn_input[event][layer].append(sampled_data[i])\n",
    "        nn_output[event][layer].append(torch.Tensor([momentum_list[i]]))\n",
    "    return nn_input, nn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e88b196c-77a7-4904-891c-222e5a5c8dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:15<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate: 0.05313160228729248 seconds / event\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "nn_input, nn_output = prepare_nn_input(processed_data, model_compile,batch_size = 50000)\n",
    "end = time.time()\n",
    "print(f\"rate: {(end - begin) / 500} seconds / event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed165349-7fa7-463f-9d66-68a30475dba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_prediction_input(nn_input, nn_output):\n",
    "    prediction_input = torch.empty(len(nn_input),28,10)\n",
    "    prediction_output = torch.empty(len(nn_input))\n",
    "    \n",
    "    input_dict = defaultdict(lambda: defaultdict(list))\n",
    "    output_dict = {}\n",
    "    for event_idx in tqdm(list(nn_input)):\n",
    "        event_input = []\n",
    "        output_dict[event_idx] = nn_output[event_idx][0][0]\n",
    "        prediction_output[event_idx] = nn_output[event_idx][0][0]\n",
    "        for layer in nn_input[event_idx].keys():\n",
    "            layer_times = torch.tensor(sorted(nn_input[event_idx][layer]))\n",
    "#             print(layer_times[:10])\n",
    "#             return\n",
    "            # Pad or truncate to exactly 10 times per layer\n",
    "            if len(layer_times) < 10:\n",
    "                padding = torch.full((10 - len(layer_times),), float('inf'))\n",
    "                layer_times = torch.cat([layer_times, padding])\n",
    "            \n",
    "            input_dict[event_idx][layer] = layer_times[:10]\n",
    "            prediction_input[event_idx][layer] = layer_times[:10]\n",
    "    return prediction_input, prediction_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "676ec2fd-ab27-4c65-bea0-daa777d0cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:24<00:00, 20.45it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction_input, prediction_output= prepare_prediction_input(nn_input,nn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad25b6c-4da2-4aa9-9b1c-137e23bf2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco import Predictor\n",
    "model = Predictor(input_size=56, num_classes=1, hidden_dim = 512, num_layers = 20)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4959f62-708a-48d5-9abf-8d89c75634b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0971)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train loop\n",
    "train_batch_size = 128\n",
    "total_data_points = prediction_output.shape[0]\n",
    "max_train_itr = total_data_points / train_batch_size\n",
    "for batch_idx in tqdm(range(max_train_itr)):\n",
    "    begin = batch_idx * train_batch_size\n",
    "    end = min((begin + train_batch_size),(total_data_points - begin))\n",
    "    batch_inputs = prediction_input[begin:end].flatten()\n",
    "    batch_outputs = prediction_output[begin:end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7678f0-f588-44b1-962c-834d69117007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
