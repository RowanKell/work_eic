{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d24741-127a-433a-9060-11ce783ea2a5",
   "metadata": {},
   "source": [
    "Goal: improve runtime efficiency and memory efficiency of pipeline\n",
    "1. Need ROOT file from hepmc file (GOOD)\n",
    "1. Process ROOT file to csv (check) (extractCellID)\n",
    "1. Generate SiPM Output (needs work) (momentum_prediction_util)\n",
    "1. Train NN (GOOD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbf44d0-d414-41ff-9224-b1f6240aba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from  pandas import read_csv as pd_read_csv\n",
    "from time_res_util import get_compiled_NF_model\n",
    "from momentum_prediction_util import SiPMSignalProcessor\n",
    "import datetime\n",
    "def print_w_time(message):\n",
    "    current_time = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    print(f\"{current_time} {message}\")\n",
    "import torch\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcb4cad-0750-4070-993c-a8fab5ba9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/core.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "# inputProcessedData = \"./data/processed_data/dev_branch_100events.csv\"\n",
    "inputProcessedData = \"./data/processed_data/dev_branch_50events.csv\"\n",
    "processed_data = pd_read_csv(inputProcessedData)\n",
    "model_compile = get_compiled_NF_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1cb35f-4354-486d-962a-45977dfaf4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:58:39 Processing data in generateSiPMOutput...\n",
      "21:58:43 starting sampling\n",
      "21:58:43 Starting batch # 1.0 / 8\n",
      "21:58:45 Starting batch # 2.0 / 8\n",
      "21:58:46 Starting batch # 3.0 / 8\n",
      "21:58:46 Starting batch # 4.0 / 8\n",
      "21:58:48 Starting batch # 5.0 / 8\n",
      "21:58:49 Starting batch # 6.0 / 8\n",
      "21:58:50 Starting batch # 7.0 / 8\n",
      "21:58:51 Starting batch # 8.0 / 8\n",
      "21:58:52 sampling took 0.14970502058664958 minutes\n",
      "21:58:52 creating df\n",
      "This cell took 50.76135444641113 seconds\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "batch_size=50000\n",
    "normalizing_flow =model_compile\n",
    "device='cuda'\n",
    "pixel_threshold = 3\n",
    "out_columns = ['event_idx','stave_idx','layer_idx','segment_idx','trueID','truePID','hitID','hitPID','P','Theta','Phi','strip_x','strip_y','strip_z','Charge1','Time1','Charge2','Time2']\n",
    "rows = []\n",
    "processor = SiPMSignalProcessor()\n",
    "normflow_input = []\n",
    "num_pixel_list = [\"num_pixels_high_z\",\"num_pixels_low_z\"]\n",
    "print_w_time(\"Processing data in generateSiPMOutput...\")\n",
    "got_row_indexes = False\n",
    "labels = []\n",
    "for row_idx, row in processed_data.iterrows():\n",
    "    for SiPM_idx in range(2):\n",
    "        num_pixel_tag = num_pixel_list[SiPM_idx] #get the name of the number of pixels for this SiPM\n",
    "        #create a new row for each of the photons/pixels\n",
    "        row_copy = row.copy()\n",
    "        row_copy['SiPM_idx'] = SiPM_idx\n",
    "        if(not got_row_indexes):\n",
    "            labels = row_copy.index.to_list()\n",
    "            got_row_indexes = True\n",
    "        normflow_input.append(torch.tensor(row_copy.values,dtype=torch.float32).repeat(int(row_copy[num_pixel_tag]), 1))\n",
    "#Create a dict like{label : index in row}\n",
    "label_dict = {}\n",
    "for i in range(len(labels)):\n",
    "    label_dict[labels[i]] = i\n",
    "\n",
    "normflow_input_tensor = torch.cat(normflow_input)\n",
    "\n",
    "data = []\n",
    "print_w_time(f\"starting sampling\")\n",
    "begin = time.time()\n",
    "#     for i in tqdm(range(0, len(normflow_input_tensor), batch_size)):\n",
    "for i in range(0, len(normflow_input_tensor), batch_size):\n",
    "    print_w_time(f\"Starting batch # {(i / batch_size) + 1} / {int(np.ceil(len(normflow_input_tensor) / batch_size))}\")\n",
    "    batch_end = min(i + batch_size, len(normflow_input_tensor))\n",
    "    batch_rows = normflow_input_tensor[i:batch_end]\n",
    "    context_indexes = [label_dict[\"z_pos\"],label_dict[\"hittheta\"],label_dict[\"hitmomentum\"]]\n",
    "    time_index = label_dict[\"time\"]\n",
    "    batch_context = batch_rows[:,context_indexes].to(device)\n",
    "    batch_particle_hit_times = batch_rows[:,time_index]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = abs(normalizing_flow.sample(num_samples=len(batch_context), context=batch_context)[0]).squeeze(1).cpu() + batch_particle_hit_times\n",
    "    batch_combined_data = torch.cat((batch_rows,samples.unsqueeze(-1)),dim = 1)\n",
    "    data.extend(batch_combined_data)\n",
    "end = time.time()\n",
    "print_w_time(f\"sampling took {(end - begin) / 60} minutes\")\n",
    "print_w_time(\"creating df\")\n",
    "labels.append(\"photon_time\")\n",
    "row_df = pd.DataFrame(data,columns = labels)\n",
    "end = time.time()\n",
    "print(f\"This cell took {end - begin} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a99e73-fc03-4b7b-a7a1-96dcb76276a7",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b941d-b204-4662-afe4-33c062d6461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:52 Beginning pulse process\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "print_w_time(\"Beginning pulse process\")\n",
    "running_index = 0\n",
    "for (event_idx, stave_idx, layer_idx, segment_idx),group in row_df.groupby(['event_idx', 'stave_idx', 'layer_idx','segment_idx']):\n",
    "#         print(f\"Starting row # {running_index}\\nevent #{event_idx}, stave #{stave_idx}, layer #{layer_idx}, segment #{segment_idx}\")\n",
    "    charge_times = torch.tensor([[0.0,0.0],[0.0,0.0]])\n",
    "    set_event_details = False\n",
    "    trigger = False\n",
    "    trueID_list_len_max = -1\n",
    "    for SiPM_idx, SiPM_group in group.groupby(['SiPM_idx']):\n",
    "        SiPM_idx_int = int(SiPM_idx[0].item())\n",
    "        #need to see if we get more than 1 hit in a segment - greg says to label this as noise\n",
    "        trueID_list_len = len(set(SiPM_group[\"trueID\"]))\n",
    "        trueID_list_len_max = max(trueID_list_len,trueID_list_len_max)\n",
    "        photon_times = torch.tensor(sorted(SiPM_group['photon_time'])) * 10 **(-9)\n",
    "        #get relative times\n",
    "        if(len(photon_times) > 0):\n",
    "            #calculate time and charge\n",
    "            time_arr,waveform = processor.generate_waveform(photon_times)\n",
    "            timing = processor.get_pulse_timing(waveform,threshold = pixel_threshold)\n",
    "            if(timing is not None):\n",
    "                curr_charge = processor.integrate_charge(waveform) * 1e6\n",
    "                curr_timing = timing * 1e8\n",
    "                charge_times[SiPM_idx_int][0] = processor.integrate_charge(waveform) * 1e6\n",
    "                charge_times[SiPM_idx_int][1] = timing * 1e8\n",
    "#                                 print(f\"SiPM idx {SiPM_idx} triggered, (time,charge) : ({curr_timing},{curr_charge})\")\n",
    "                trigger = True\n",
    "            else: #no trigger, don't set details yet\n",
    "                continue\n",
    "            if(not set_event_details):\n",
    "                #take the 0th one - if there are multiple, then these are noise anyways\n",
    "                P = SiPM_group['truemomentum'].iloc[0]\n",
    "                trueID = SiPM_group['trueID'].iloc[0]\n",
    "                truePID = SiPM_group['truePID'].iloc[0]\n",
    "                hitID = SiPM_group['hitID'].iloc[0]\n",
    "                hitPID = SiPM_group['hitPID'].iloc[0]\n",
    "                theta = SiPM_group['truetheta'].iloc[0]\n",
    "                phi = SiPM_group['truephi'].iloc[0]\n",
    "                strip_x = SiPM_group['strip_x'].iloc[0]\n",
    "                strip_y = SiPM_group['strip_y'].iloc[0]\n",
    "                strip_z = SiPM_group['strip_z'].iloc[0]\n",
    "                set_event_details = True\n",
    "        else: #no photons, no data\n",
    "            continue\n",
    "    if(not set_event_details):\n",
    "        continue\n",
    "    if (not trigger):\n",
    "        continue;\n",
    "    noise = False\n",
    "    if(trueID_list_len_max > 1):\n",
    "        noise = True\n",
    "    if(not noise):\n",
    "        if(trueID_dict[event_idx][trueID.item()] == -1):\n",
    "            trueID_dict[event_idx][trueID.item()] = trueID_dict_running_idx\n",
    "            trueID_dict_running_idx += 1\n",
    "        translated_trueID = trueID_dict[event_idx][trueID.item()]\n",
    "    else:\n",
    "        translated_trueID = -1\n",
    "    new_row = { \n",
    "       out_columns[0] : event_idx,\n",
    "       out_columns[1] : stave_idx,\n",
    "       out_columns[2] : layer_idx,\n",
    "       out_columns[3] : segment_idx,\n",
    "       out_columns[4] : translated_trueID, \n",
    "       \"original_trueID\" : trueID.item(), \n",
    "       out_columns[5] : truePID.item(), \n",
    "       out_columns[6] : hitID.item(),\n",
    "       out_columns[7] : hitPID.item(),\n",
    "       out_columns[8] : P.item(), \n",
    "       out_columns[9] : theta.item(), \n",
    "      out_columns[10] : phi.item(), \n",
    "      out_columns[11] : strip_z.item(), \n",
    "      out_columns[12] : strip_x.item(), \n",
    "      out_columns[13] : strip_y.item(), \n",
    "      out_columns[14] : charge_times[0,0].item(), \n",
    "      out_columns[15] : charge_times[0,1].item(), \n",
    "      out_columns[16] : charge_times[1,0].item(), \n",
    "      out_columns[17] : charge_times[1,1].item(),\n",
    "    }\n",
    "    rows.append(new_row)\n",
    "    running_index += 1\n",
    "df = pd.DataFrame(rows,columns = out_columns)\n",
    "end = time.time()\n",
    "print(f\"Original Method took {(end - begin)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df89fa6-3944-478b-8e02-892d7bb8233b",
   "metadata": {},
   "source": [
    "#### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a18404af-84ac-44d6-82e1-4367d9665e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n",
      "New method took 70.85411930084229 seconds\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "results = []\n",
    "\n",
    "trueID_dict = defaultdict(lambda: defaultdict(lambda: -1))\n",
    "trueID_dict_running_idx = 0\n",
    "\n",
    "\n",
    "# Get the column values as numpy arrays for faster access\n",
    "event_indices = row_df['event_idx'].values\n",
    "stave_indices = row_df['stave_idx'].values\n",
    "layer_indices = row_df['layer_idx'].values\n",
    "segment_indices = row_df['segment_idx'].values\n",
    "\n",
    "current_indices = [-1, -1, -1, -1]  # [event, stave, layer, segment]\n",
    "segment_start = 0\n",
    "running_segment_idx = 0\n",
    "# loop over all hits in df\n",
    "for i in range(len(row_df) + 1):\n",
    "    # Check if we've reached a new segment or the end of the dataset\n",
    "    if i == len(row_df) or (\n",
    "        event_indices[i] != current_indices[0] or\n",
    "        stave_indices[i] != current_indices[1] or\n",
    "        layer_indices[i] != current_indices[2] or\n",
    "        segment_indices[i] != current_indices[3]\n",
    "    ):\n",
    "        # Process the previous segment if it exists\n",
    "        if current_indices[0] != -1:\n",
    "            #get all hits in segment\n",
    "            segment_data = row_df.iloc[segment_start:i]\n",
    "            running_segment_idx += 1\n",
    "#             print(f\"processing segment #{running_segment_idx}\")\n",
    "            clear_output(wait=True)\n",
    "            # Your processing logic here\n",
    "            \n",
    "            \n",
    "            charge_times = torch.tensor([[0.0,0.0],[0.0,0.0]])\n",
    "            set_event_details = False\n",
    "            trigger = False\n",
    "            trueID_list_len_max = -1\n",
    "            for SiPM_idx, SiPM_group in segment_data.groupby(['SiPM_idx']):\n",
    "                SiPM_idx_int = int(SiPM_idx[0].item())\n",
    "                #need to see if we get more than 1 hit in a segment - greg says to label this as noise\n",
    "                trueID_list_len = len(set(SiPM_group[\"trueID\"].apply(lambda x: x.item())))\n",
    "                trueID_list_len_max = max(trueID_list_len,trueID_list_len_max)\n",
    "                photon_times = torch.tensor(SiPM_group[\"photon_time\"].to_list()) * 10 **(-9)\n",
    "                #get relative times\n",
    "                if(len(photon_times) > 0):\n",
    "                    #calculate time and charge\n",
    "                    time_arr,waveform = processor.generate_waveform(photon_times)\n",
    "                    timing = processor.get_pulse_timing(waveform,threshold = pixel_threshold)\n",
    "                    if(timing is not None):\n",
    "                        curr_charge = processor.integrate_charge(waveform) * 1e6\n",
    "                        curr_timing = timing * 1e8\n",
    "                        charge_times[SiPM_idx_int][0] = processor.integrate_charge(waveform) * 1e6\n",
    "                        charge_times[SiPM_idx_int][1] = timing * 1e8\n",
    "        #                                 print(f\"SiPM idx {SiPM_idx} triggered, (time,charge) : ({curr_timing},{curr_charge})\")\n",
    "                        trigger = True\n",
    "                    else: #no trigger, don't set details yet\n",
    "                        continue\n",
    "                    if(not set_event_details):\n",
    "                        #take the 0th one - if there are multiple, then these are noise anyways\n",
    "                        P = SiPM_group['truemomentum'].iloc[0]\n",
    "                        trueID = SiPM_group['trueID'].iloc[0]\n",
    "                        truePID = SiPM_group['truePID'].iloc[0]\n",
    "                        hitID = SiPM_group['hitID'].iloc[0]\n",
    "                        hitPID = SiPM_group['hitPID'].iloc[0]\n",
    "                        theta = SiPM_group['truetheta'].iloc[0]\n",
    "                        phi = SiPM_group['truephi'].iloc[0]\n",
    "                        strip_x = SiPM_group['strip_x'].iloc[0]\n",
    "                        strip_y = SiPM_group['strip_y'].iloc[0]\n",
    "                        strip_z = SiPM_group['strip_z'].iloc[0]\n",
    "                        set_event_details = True\n",
    "                else: #no photons, no data\n",
    "                    continue\n",
    "            noise = False\n",
    "            if(trueID_list_len_max > 1):\n",
    "                noise = True\n",
    "            if(not noise):\n",
    "                if(trueID_dict[current_indices[0]][trueID.item()] == -1):\n",
    "                    trueID_dict[current_indices[0]][trueID.item()] = trueID_dict_running_idx\n",
    "                    trueID_dict_running_idx += 1\n",
    "                translated_trueID = trueID_dict[current_indices[0]][trueID.item()]\n",
    "            else:\n",
    "                translated_trueID = -1\n",
    "            if(set_event_details) and (trigger):\n",
    "#                 print(\"Adding new row\")\n",
    "                new_row = { \n",
    "                   out_columns[0] : current_indices[0],\n",
    "                   out_columns[1] : current_indices[1],\n",
    "                   out_columns[2] : current_indices[2],\n",
    "                   out_columns[3] : current_indices[3],\n",
    "                   out_columns[4] : translated_trueID, \n",
    "                   \"original_trueID\" : trueID.item(), \n",
    "                   out_columns[5] : truePID.item(), \n",
    "                   out_columns[6] : hitID.item(),\n",
    "                   out_columns[7] : hitPID.item(),\n",
    "                   out_columns[8] : P.item(), \n",
    "                   out_columns[9] : theta.item(), \n",
    "                  out_columns[10] : phi.item(), \n",
    "                  out_columns[11] : strip_z.item(), \n",
    "                  out_columns[12] : strip_x.item(), \n",
    "                  out_columns[13] : strip_y.item(), \n",
    "                  out_columns[14] : charge_times[0,0].item(), \n",
    "                  out_columns[15] : charge_times[0,1].item(), \n",
    "                  out_columns[16] : charge_times[1,0].item(), \n",
    "                  out_columns[17] : charge_times[1,1].item(),\n",
    "                }\n",
    "                results.append(new_row)\n",
    "        if i < len(row_df):\n",
    "            # Update indices for the new segment\n",
    "            current_indices = [\n",
    "                event_indices[i],\n",
    "                stave_indices[i],\n",
    "                layer_indices[i],\n",
    "                segment_indices[i]\n",
    "            ]\n",
    "            #save the index of the beginning of segment so we know\n",
    "            #which hits are in this segment\n",
    "            segment_start = i\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "print(f\"Finished\")\n",
    "end = time.time()\n",
    "print(f\"New method took {end - begin} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdca272f-d2ac-4947-8e53-bd792393ede6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_idx</th>\n",
       "      <th>stave_idx</th>\n",
       "      <th>layer_idx</th>\n",
       "      <th>segment_idx</th>\n",
       "      <th>trueID</th>\n",
       "      <th>original_trueID</th>\n",
       "      <th>truePID</th>\n",
       "      <th>hitID</th>\n",
       "      <th>hitPID</th>\n",
       "      <th>P</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Phi</th>\n",
       "      <th>strip_x</th>\n",
       "      <th>strip_y</th>\n",
       "      <th>strip_z</th>\n",
       "      <th>Charge1</th>\n",
       "      <th>Time1</th>\n",
       "      <th>Charge2</th>\n",
       "      <th>Time2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(14.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(9.)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000220e+09</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>101.730644</td>\n",
       "      <td>-58.716457</td>\n",
       "      <td>96.910843</td>\n",
       "      <td>-159.592148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101561</td>\n",
       "      <td>3.589461</td>\n",
       "      <td>0.330018</td>\n",
       "      <td>3.554926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(14.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(11.)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.112000e+03</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>101.730644</td>\n",
       "      <td>-58.716457</td>\n",
       "      <td>101.231018</td>\n",
       "      <td>-155.271973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139634</td>\n",
       "      <td>3.669460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(14.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(10.)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>101.730644</td>\n",
       "      <td>-58.716457</td>\n",
       "      <td>99.070930</td>\n",
       "      <td>-157.432053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>3.569203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(14.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(8.)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.112000e+03</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>101.730644</td>\n",
       "      <td>-58.716457</td>\n",
       "      <td>94.750755</td>\n",
       "      <td>-161.752228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088839</td>\n",
       "      <td>3.590492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(14.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.000241e+09</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>101.730644</td>\n",
       "      <td>-58.716457</td>\n",
       "      <td>88.270493</td>\n",
       "      <td>-168.232498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050762</td>\n",
       "      <td>3.869566</td>\n",
       "      <td>0.241107</td>\n",
       "      <td>3.698899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tensor(30.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>tensor(11.)</td>\n",
       "      <td>tensor(25.)</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2.112000e+03</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>91.994919</td>\n",
       "      <td>89.898590</td>\n",
       "      <td>31.580360</td>\n",
       "      <td>265.744995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050807</td>\n",
       "      <td>2.942153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tensor(30.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>tensor(11.)</td>\n",
       "      <td>tensor(36.)</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1.000251e+09</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>91.994919</td>\n",
       "      <td>89.898590</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>265.744995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127055</td>\n",
       "      <td>2.202142</td>\n",
       "      <td>0.050825</td>\n",
       "      <td>2.145680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tensor(30.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>tensor(11.)</td>\n",
       "      <td>tensor(35.)</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>91.994919</td>\n",
       "      <td>89.898590</td>\n",
       "      <td>1.507306</td>\n",
       "      <td>265.744995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063528</td>\n",
       "      <td>2.236315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tensor(30.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>tensor(12.)</td>\n",
       "      <td>tensor(37.)</td>\n",
       "      <td>254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>91.994919</td>\n",
       "      <td>89.898590</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>273.415009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254108</td>\n",
       "      <td>2.229747</td>\n",
       "      <td>0.050819</td>\n",
       "      <td>2.365991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tensor(30.)</td>\n",
       "      <td>tensor(5.)</td>\n",
       "      <td>tensor(12.)</td>\n",
       "      <td>tensor(35.)</td>\n",
       "      <td>255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.000060e+09</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>91.994919</td>\n",
       "      <td>89.898590</td>\n",
       "      <td>4.523785</td>\n",
       "      <td>275.505005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050822</td>\n",
       "      <td>2.340172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_idx   stave_idx    layer_idx  segment_idx  trueID  \\\n",
       "0    tensor(14.)  tensor(0.)   tensor(0.)   tensor(9.)       0   \n",
       "1    tensor(14.)  tensor(0.)   tensor(0.)  tensor(11.)       1   \n",
       "2    tensor(14.)  tensor(0.)   tensor(0.)  tensor(10.)       2   \n",
       "3    tensor(14.)  tensor(0.)   tensor(0.)   tensor(8.)       3   \n",
       "4    tensor(14.)  tensor(0.)   tensor(0.)   tensor(5.)       4   \n",
       "..           ...         ...          ...          ...     ...   \n",
       "190  tensor(30.)  tensor(5.)  tensor(11.)  tensor(25.)     251   \n",
       "191  tensor(30.)  tensor(5.)  tensor(11.)  tensor(36.)     252   \n",
       "192  tensor(30.)  tensor(5.)  tensor(11.)  tensor(35.)     253   \n",
       "193  tensor(30.)  tensor(5.)  tensor(12.)  tensor(37.)     254   \n",
       "194  tensor(30.)  tensor(5.)  tensor(12.)  tensor(35.)     255   \n",
       "\n",
       "     original_trueID  truePID  hitID        hitPID         P       Theta  \\\n",
       "0                0.0    130.0   14.0  1.000220e+09  0.150235  101.730644   \n",
       "1                0.0    130.0    9.0  2.112000e+03  0.150235  101.730644   \n",
       "2                0.0    130.0   45.0  1.100000e+01  0.150235  101.730644   \n",
       "3                0.0    130.0   31.0  2.112000e+03  0.150235  101.730644   \n",
       "4                0.0    130.0   54.0  1.000241e+09  0.150235  101.730644   \n",
       "..               ...      ...    ...           ...       ...         ...   \n",
       "190              0.0    130.0  394.0  2.112000e+03  1.220183   91.994919   \n",
       "191              0.0    130.0  460.0  1.000251e+09  1.220183   91.994919   \n",
       "192              0.0    130.0  465.0  1.100000e+01  1.220183   91.994919   \n",
       "193              0.0    130.0  462.0  1.100000e+01  1.220183   91.994919   \n",
       "194              0.0    130.0  472.0  1.000060e+09  1.220183   91.994919   \n",
       "\n",
       "           Phi     strip_x     strip_y  strip_z   Charge1     Time1   Charge2  \\\n",
       "0   -58.716457   96.910843 -159.592148      0.0  0.101561  3.589461  0.330018   \n",
       "1   -58.716457  101.231018 -155.271973      0.0  0.000000  0.000000  0.139634   \n",
       "2   -58.716457   99.070930 -157.432053      0.0  0.000000  0.000000  0.101545   \n",
       "3   -58.716457   94.750755 -161.752228      0.0  0.000000  0.000000  0.088839   \n",
       "4   -58.716457   88.270493 -168.232498      0.0  0.050762  3.869566  0.241107   \n",
       "..         ...         ...         ...      ...       ...       ...       ...   \n",
       "190  89.898590   31.580360  265.744995      0.0  0.000000  0.000000  0.050807   \n",
       "191  89.898590   -1.500000  265.744995      0.0  0.127055  2.202142  0.050825   \n",
       "192  89.898590    1.507306  265.744995      0.0  0.063528  2.236315  0.000000   \n",
       "193  89.898590   -1.500000  273.415009      0.0  0.254108  2.229747  0.050819   \n",
       "194  89.898590    4.523785  275.505005      0.0  0.050822  2.340172  0.000000   \n",
       "\n",
       "        Time2  \n",
       "0    3.554926  \n",
       "1    3.669460  \n",
       "2    3.569203  \n",
       "3    3.590492  \n",
       "4    3.698899  \n",
       "..        ...  \n",
       "190  2.942153  \n",
       "191  2.145680  \n",
       "192  0.000000  \n",
       "193  2.365991  \n",
       "194  0.000000  \n",
       "\n",
       "[195 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86062a99-badc-4cad-bbe3-157d06624fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93213fb5-ec4a-45f9-b971-43f466aeaf95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
